# Core Kubernetes client
kubernetes==28.1.0

# HTTP client for ArgoCD integration and Ollama
requests==2.31.0

# Configuration management
pyyaml==6.0.1

# Async HTTP for better performance
aiohttp==3.9.1

# Structured logging
structlog==23.2.0

# Optional monitoring (FREE)
prometheus-client==0.19.0

# LOCAL LLM OPTIONS (install as needed):

# Option 1: Ollama client (recommended - easiest setup)
# No additional packages needed - uses requests

# Option 2: Hugging Face Transformers (more resource intensive)
# Uncomment these for local transformer models:
# torch>=2.0.0
# transformers>=4.30.0
# accelerate>=0.20.0

# Option 3: llama-cpp-python (lightweight C++ implementation)
# llama-cpp-python>=0.2.0

# Development and testing
pytest==7.4.4
pytest-asyncio==0.21.1
black==23.11.0
flake8==6.1.0

# ALL LOCAL - NO PAID APIs!
